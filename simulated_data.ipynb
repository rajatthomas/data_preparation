{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import os \n",
    "from itertools import product\n",
    "\n",
    "import warnings\n",
    "\n",
    "#from modshogun import *\n",
    "\n",
    "from sklearn import linear_model, decomposition\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold, LeaveOneGroupOut\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder, StandardScaler, Imputer, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from CustomCVs import KFoldMixedSizes, StratifiedKFoldMixedSizes, StratifiedKFoldByGroups\n",
    "#from evaluation_classifier import Evaluater\n",
    "\n",
    "from time import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#from fancyimpute import BiScaler, KNN, NuclearNormMinimization, SoftImpute, IterativeSVD #, MICE\n",
    "\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_rank_k_dataset(\n",
    "#         n_rows=5,\n",
    "#         n_cols=5,\n",
    "#         k=3,\n",
    "#         fraction_missing=0.1,\n",
    "#         symmetric=False,\n",
    "#         random_seed=0):\n",
    "#     np.random.seed(random_seed)\n",
    "#     x = np.random.randn(n_rows, k)\n",
    "#     y = np.random.randn(k, n_cols)\n",
    "\n",
    "#     XY = np.dot(x, y)\n",
    "\n",
    "#     if symmetric:\n",
    "#         assert n_rows == n_cols\n",
    "#         XY = 0.5 * XY + 0.5 * XY.T\n",
    "\n",
    "#     missing_raw_values = np.random.uniform(0, 1, (n_rows, n_cols))\n",
    "#     missing_mask = missing_raw_values < fraction_missing\n",
    "\n",
    "#     XY_incomplete = XY.copy()\n",
    "#     # fill missing entries with NaN\n",
    "#     XY_incomplete[missing_mask] = np.nan\n",
    "\n",
    "#     return XY, XY_incomplete, missing_mask\n",
    "\n",
    "# # create some default data to be shared across tests\n",
    "# XY, XY_incomplete, missing_mask = create_rank_k_dataset(\n",
    "#     n_rows=500,\n",
    "#     n_cols=10,\n",
    "#     k=3,\n",
    "#     fraction_missing=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_correlated_dataset(cov_mat, n_obs = 2500):\n",
    "    \n",
    "    n_vars = cov_mat.shape[0]\n",
    "    cov_mat = cov_mat + 1 * np.eye(n_vars) # regularize for stability\n",
    "    \n",
    "    try:\n",
    "        L = np.linalg.cholesky(cov_mat)\n",
    "        D = np.dot(L, np.random.uniform(0,1, (n_vars, n_obs)))\n",
    "        return D\n",
    "    \n",
    "    except np.linalg.LinAlgError as err:\n",
    "        print('Error ---- Cholesksy')\n",
    "        return None\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.37224904, 0.36230115, 0.20353479],\n",
       "       [0.37224904, 1.        , 0.48604921, 0.12585383],\n",
       "       [0.36230115, 0.48604921, 1.        , 0.16007137],\n",
       "       [0.20353479, 0.12585383, 0.16007137, 1.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "cov_mat = np.array([[1, 0.7, 0.7, 0.5,],\n",
    "             [0.7, 1, 0.95, 0.3],\n",
    "             [0.7, 0.95, 1, 0.3],\n",
    "             [0.5, 0.3, 0.3, 1]])\n",
    "\n",
    "D = create_correlated_dataset(cov_mat)\n",
    "print(D.shape)\n",
    "np.corrcoef(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2500)\n"
     ]
    }
   ],
   "source": [
    "# Construct a cov matrix using a REAL dataset\n",
    "\n",
    "data_dir=\"/data/rmthomas/HeteroSmallSample\"\n",
    "df = pd.read_csv(os.path.join(data_dir, \"real_data.csv\"))\n",
    "df_numeric = df[df.columns[25:125]]\n",
    "cov_mat_overall = df_numeric.corr().values\n",
    "\n",
    "alpha = 0.2\n",
    "reg_cov_mat = cov_mat_overall + alpha*np.eye(100) # alpha makes the matrix well conditioned for Cholesky\n",
    "D_overall = create_correlated_dataset(reg_cov_mat)\n",
    "print(D_overall.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 100 \n",
    "g = df.groupby(['site', 'Dx', 'age_group'])[df.columns[25:25+n_features]]\n",
    "\n",
    "Groups = list(g.indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate correlation matrices per set = (site, Dx, age_group)\n",
    "corrs_per_set = g.corr().values.reshape(-1, n_features, n_features)\n",
    "#corrs_per_set[np.where(np.isnan(corrs_per_set))] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_labels = [f'f{i}' for i in range(100)] # f1, f2 ...f100\n",
    "data_cols = ['site', 'Dx', 'Age_group'] + feature_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data_all = pd.DataFrame(columns=data_cols) # initialize a dataframe\n",
    "group_template = pd.DataFrame(columns=['site', 'Dx', 'Age_group']) # initialize a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error ---- Cholesksy\n",
      "Error ---- Cholesksy\n",
      "Error ---- Cholesksy\n",
      "Error ---- Cholesksy\n",
      "Error ---- Cholesksy\n",
      "Error ---- Cholesksy\n",
      "Error ---- Cholesksy\n",
      "Error ---- Cholesksy\n",
      "Error ---- Cholesksy\n",
      "Error ---- Cholesksy\n",
      "Error ---- Cholesksy\n",
      "Error ---- Cholesksy\n",
      "Error ---- Cholesksy\n",
      "Error ---- Cholesksy\n"
     ]
    }
   ],
   "source": [
    "sim_data=[]\n",
    "\n",
    "min_subj = 5\n",
    "max_subj = 70\n",
    "for corr_i in range(corrs_per_set.shape[0]):\n",
    "    n_obs=np.random.choice(np.arange(min_subj, max_subj))\n",
    "    D = create_correlated_dataset(corrs_per_set[corr_i], n_obs=n_obs)\n",
    "\n",
    "    if D is not None:\n",
    "        sim_data_group = pd.DataFrame([list(Groups[corr_i])], columns=['site', 'Dx', 'Age_group'])\n",
    "        sim_data_group = pd.concat([sim_data_group]*n_obs, ignore_index=True)\n",
    "        \n",
    "        sim_data_group_matrix = pd.DataFrame(D.T, columns=feature_labels)\n",
    "        df_group = pd.concat([sim_data_group, sim_data_group_matrix], axis=1, ignore_index=False)\n",
    "        sim_data_all = sim_data_all.append(df_group, ignore_index=True)\n",
    "        sim_data.append(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Arnold', 'Benedetti', 'Beucke', 'Brennan', 'Buitelaar', 'Cheng',\n",
       "       'Fitzgerald', 'Gruner', 'Heuvel', 'Hirano', 'Hoexter', 'Huyser',\n",
       "       'Koch', 'Kwon', 'KwonNMC', 'KwonSNU', 'Lazaro', 'Marsh',\n",
       "       'Mataix_Cols', 'Menchon', 'Morgado', 'Nakamae', 'Nakao', 'Nurmi',\n",
       "       'Reddy', 'Simpson', 'Soreni', 'Spalletta', 'Stein', 'Stewart',\n",
       "       'Tolin', 'Walitza', 'Wang'], dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_data_all['site'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>Dx</th>\n",
       "      <th>Age_group</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>...</th>\n",
       "      <th>f90</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arnold</td>\n",
       "      <td>1</td>\n",
       "      <td>2_pediatric</td>\n",
       "      <td>0.951022</td>\n",
       "      <td>1.512775</td>\n",
       "      <td>1.714066</td>\n",
       "      <td>2.085525</td>\n",
       "      <td>2.231103</td>\n",
       "      <td>1.757755</td>\n",
       "      <td>0.704306</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.886497</td>\n",
       "      <td>0.890936</td>\n",
       "      <td>0.236274</td>\n",
       "      <td>0.526358</td>\n",
       "      <td>-0.286389</td>\n",
       "      <td>0.812563</td>\n",
       "      <td>-0.166830</td>\n",
       "      <td>0.611281</td>\n",
       "      <td>-0.342606</td>\n",
       "      <td>-0.269540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arnold</td>\n",
       "      <td>1</td>\n",
       "      <td>2_pediatric</td>\n",
       "      <td>1.063553</td>\n",
       "      <td>0.551570</td>\n",
       "      <td>1.340835</td>\n",
       "      <td>1.222201</td>\n",
       "      <td>1.476826</td>\n",
       "      <td>0.992264</td>\n",
       "      <td>0.930643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.549631</td>\n",
       "      <td>0.704089</td>\n",
       "      <td>0.691332</td>\n",
       "      <td>-0.115608</td>\n",
       "      <td>0.188352</td>\n",
       "      <td>0.469429</td>\n",
       "      <td>0.342107</td>\n",
       "      <td>0.171521</td>\n",
       "      <td>0.303544</td>\n",
       "      <td>-1.086232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arnold</td>\n",
       "      <td>1</td>\n",
       "      <td>2_pediatric</td>\n",
       "      <td>1.248328</td>\n",
       "      <td>0.760264</td>\n",
       "      <td>1.374774</td>\n",
       "      <td>0.790993</td>\n",
       "      <td>0.683645</td>\n",
       "      <td>0.987078</td>\n",
       "      <td>0.270414</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.519217</td>\n",
       "      <td>0.439890</td>\n",
       "      <td>0.303501</td>\n",
       "      <td>0.510986</td>\n",
       "      <td>0.004420</td>\n",
       "      <td>0.359330</td>\n",
       "      <td>0.584917</td>\n",
       "      <td>0.718951</td>\n",
       "      <td>-0.409061</td>\n",
       "      <td>-0.553637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arnold</td>\n",
       "      <td>1</td>\n",
       "      <td>2_pediatric</td>\n",
       "      <td>0.291278</td>\n",
       "      <td>0.569711</td>\n",
       "      <td>0.356906</td>\n",
       "      <td>0.871737</td>\n",
       "      <td>0.580628</td>\n",
       "      <td>0.767636</td>\n",
       "      <td>0.646040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117505</td>\n",
       "      <td>0.902192</td>\n",
       "      <td>0.944374</td>\n",
       "      <td>0.074966</td>\n",
       "      <td>0.814591</td>\n",
       "      <td>-0.170715</td>\n",
       "      <td>0.317569</td>\n",
       "      <td>0.232148</td>\n",
       "      <td>0.518169</td>\n",
       "      <td>-0.931058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arnold</td>\n",
       "      <td>1</td>\n",
       "      <td>2_pediatric</td>\n",
       "      <td>0.176449</td>\n",
       "      <td>0.717307</td>\n",
       "      <td>1.171825</td>\n",
       "      <td>1.235284</td>\n",
       "      <td>0.837378</td>\n",
       "      <td>1.454417</td>\n",
       "      <td>0.745621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.335837</td>\n",
       "      <td>0.598034</td>\n",
       "      <td>0.735613</td>\n",
       "      <td>0.051320</td>\n",
       "      <td>0.293834</td>\n",
       "      <td>0.840017</td>\n",
       "      <td>0.869743</td>\n",
       "      <td>0.593250</td>\n",
       "      <td>0.503287</td>\n",
       "      <td>-1.125220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     site Dx    Age_group        f0        f1        f2        f3        f4  \\\n",
       "0  Arnold  1  2_pediatric  0.951022  1.512775  1.714066  2.085525  2.231103   \n",
       "1  Arnold  1  2_pediatric  1.063553  0.551570  1.340835  1.222201  1.476826   \n",
       "2  Arnold  1  2_pediatric  1.248328  0.760264  1.374774  0.790993  0.683645   \n",
       "3  Arnold  1  2_pediatric  0.291278  0.569711  0.356906  0.871737  0.580628   \n",
       "4  Arnold  1  2_pediatric  0.176449  0.717307  1.171825  1.235284  0.837378   \n",
       "\n",
       "         f5        f6    ...          f90       f91       f92       f93  \\\n",
       "0  1.757755  0.704306    ...    -0.886497  0.890936  0.236274  0.526358   \n",
       "1  0.992264  0.930643    ...    -0.549631  0.704089  0.691332 -0.115608   \n",
       "2  0.987078  0.270414    ...    -0.519217  0.439890  0.303501  0.510986   \n",
       "3  0.767636  0.646040    ...    -0.117505  0.902192  0.944374  0.074966   \n",
       "4  1.454417  0.745621    ...    -0.335837  0.598034  0.735613  0.051320   \n",
       "\n",
       "        f94       f95       f96       f97       f98       f99  \n",
       "0 -0.286389  0.812563 -0.166830  0.611281 -0.342606 -0.269540  \n",
       "1  0.188352  0.469429  0.342107  0.171521  0.303544 -1.086232  \n",
       "2  0.004420  0.359330  0.584917  0.718951 -0.409061 -0.553637  \n",
       "3  0.814591 -0.170715  0.317569  0.232148  0.518169 -0.931058  \n",
       "4  0.293834  0.840017  0.869743  0.593250  0.503287 -1.125220  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_data_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1213, 103)\n",
      "(1337, 103)\n"
     ]
    }
   ],
   "source": [
    "print(sim_data_all[sim_data_all['Dx']==1].shape)\n",
    "print(sim_data_all[sim_data_all['Dx']==0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = np.hstack(sim_data)\n",
    "nvars, nsubjs = all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data for each group\n",
    "D_patients = create_correlated_dataset(cov_patients)\n",
    "D_controls = create_correlated_dataset(cov_controls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gs\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "a = 31\n",
    "if a%2 != 0:\n",
    "    a += 1\n",
    "\n",
    "n = np.floor(np.sqrt(a)).astype(np.int64)\n",
    "\n",
    "while a%n != 0:\n",
    "    n -= 1\n",
    "\n",
    "m = (a/n).astype(np.int64)\n",
    "coords = list(itertools.product(list(range(m)), list(range(n))))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fancyimpute import MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/athi94/investigating-imputation-methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
