{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import os \n",
    "from itertools import product\n",
    "\n",
    "import warnings\n",
    "\n",
    "#from modshogun import *\n",
    "\n",
    "from sklearn import linear_model, decomposition\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold, LeaveOneGroupOut\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder, StandardScaler, Imputer, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from CustomCVs import KFoldMixedSizes, StratifiedKFoldMixedSizes, StratifiedKFoldByGroups\n",
    "#from evaluation_classifier import Evaluater\n",
    "\n",
    "from time import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#from fancyimpute import BiScaler, KNN, NuclearNormMinimization, SoftImpute, IterativeSVD #, MICE\n",
    "\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rank_k_dataset(\n",
    "        n_rows=5,\n",
    "        n_cols=5,\n",
    "        k=3,\n",
    "        fraction_missing=0.1,\n",
    "        symmetric=False,\n",
    "        random_seed=0):\n",
    "    np.random.seed(random_seed)\n",
    "    x = np.random.randn(n_rows, k)\n",
    "    y = np.random.randn(k, n_cols)\n",
    "\n",
    "    XY = np.dot(x, y)\n",
    "\n",
    "    if symmetric:\n",
    "        assert n_rows == n_cols\n",
    "        XY = 0.5 * XY + 0.5 * XY.T\n",
    "\n",
    "    missing_raw_values = np.random.uniform(0, 1, (n_rows, n_cols))\n",
    "    missing_mask = missing_raw_values < fraction_missing\n",
    "\n",
    "    XY_incomplete = XY.copy()\n",
    "    # fill missing entries with NaN\n",
    "    XY_incomplete[missing_mask] = np.nan\n",
    "\n",
    "    return XY, XY_incomplete, missing_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some default data to be shared across tests\n",
    "XY, XY_incomplete, missing_mask = create_rank_k_dataset(\n",
    "    n_rows=500,\n",
    "    n_cols=10,\n",
    "    k=3,\n",
    "    fraction_missing=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_correlated_dataset(cov_mat, n_obs = 2500):\n",
    "    \n",
    "    n_vars = cov_mat.shape[0]\n",
    "    \n",
    "    L = np.linalg.cholesky(cov_mat)\n",
    "    D = np.dot(L, np.random.uniform(0,1, (n_vars, n_obs)))\n",
    "    \n",
    "    return D\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.70117498, 0.70252767, 0.50443589],\n",
       "       [0.70117498, 1.        , 0.94965823, 0.29018632],\n",
       "       [0.70252767, 0.94965823, 1.        , 0.28468454],\n",
       "       [0.50443589, 0.29018632, 0.28468454, 1.        ]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "cov_mat = np.array([[1, 0.7, 0.7, 0.5,],\n",
    "             [0.7, 1, 0.95, 0.3],\n",
    "             [0.7, 0.95, 1, 0.3],\n",
    "             [0.5, 0.3, 0.3, 1]])\n",
    "\n",
    "D = create_correlated_dataset(cov_mat)\n",
    "print(D.shape)\n",
    "np.corrcoef(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2500)\n"
     ]
    }
   ],
   "source": [
    "# Construct a cov matrix using a REAL dataset\n",
    "\n",
    "data_dir=\"/data/rmthomas/HeteroSmallSample\"\n",
    "df = pd.read_csv(os.path.join(data_dir, \"real_data.csv\"))\n",
    "df_numeric = df[df.columns[25:125]]\n",
    "cov_mat_overall = df_numeric.corr().values\n",
    "\n",
    "alpha = 0.2\n",
    "reg_cov_mat = cov_mat_overall + alpha*np.eye(100) # alpha makes the matrix well conditioned for Cholesky\n",
    "D_overall = create_correlated_dataset(reg_cov_mat)\n",
    "print(D_overall.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = df.groupby(['site', 'Dx', 'age_group'])[df.columns[25:125]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = df.groupby(['Dx'])[df.columns[25:125]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 100)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.corr().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a separate correlation matrix for controls and patients\n",
    "cov_patients = g.corr().values[:100, :]\n",
    "cov_controls = g.corr().values[100:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data for each group\n",
    "D_patients = create_correlated_dataset(cov_patients)\n",
    "D_controls = create_correlated_dataset(cov_controls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge and randomize to create the final features X subjects matrix\n",
    "D = np.hstack((D_patients, D_controls))\n",
    "D = D[:, np.random.permutation(D.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fancyimpute import MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-110-fd69fde1077d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-110-fd69fde1077d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    https://www.kaggle.com/athi94/investigating-imputation-methods\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "https://www.kaggle.com/athi94/investigating-imputation-methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
