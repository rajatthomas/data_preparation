{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import os \n",
    "from itertools import product\n",
    "\n",
    "import warnings\n",
    "\n",
    "#from modshogun import *\n",
    "\n",
    "from sklearn import linear_model, decomposition\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold, LeaveOneGroupOut\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder, StandardScaler, Imputer, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from CustomCVs import KFoldMixedSizes, StratifiedKFoldMixedSizes, StratifiedKFoldByGroups\n",
    "#from evaluation_classifier import Evaluater\n",
    "\n",
    "from time import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#from fancyimpute import BiScaler, KNN, NuclearNormMinimization, SoftImpute, IterativeSVD #, MICE\n",
    "\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rank_k_dataset(\n",
    "        n_rows=5,\n",
    "        n_cols=5,\n",
    "        k=3,\n",
    "        fraction_missing=0.1,\n",
    "        symmetric=False,\n",
    "        random_seed=0):\n",
    "    np.random.seed(random_seed)\n",
    "    x = np.random.randn(n_rows, k)\n",
    "    y = np.random.randn(k, n_cols)\n",
    "\n",
    "    XY = np.dot(x, y)\n",
    "\n",
    "    if symmetric:\n",
    "        assert n_rows == n_cols\n",
    "        XY = 0.5 * XY + 0.5 * XY.T\n",
    "\n",
    "    missing_raw_values = np.random.uniform(0, 1, (n_rows, n_cols))\n",
    "    missing_mask = missing_raw_values < fraction_missing\n",
    "\n",
    "    XY_incomplete = XY.copy()\n",
    "    # fill missing entries with NaN\n",
    "    XY_incomplete[missing_mask] = np.nan\n",
    "\n",
    "    return XY, XY_incomplete, missing_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some default data to be shared across tests\n",
    "XY, XY_incomplete, missing_mask = create_rank_k_dataset(\n",
    "    n_rows=500,\n",
    "    n_cols=10,\n",
    "    k=3,\n",
    "    fraction_missing=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_correlated_dataset(cov_mat, n_obs = 2500):\n",
    "    \n",
    "    n_vars = cov_mat.shape[0]\n",
    "    cov_mat = cov_mat + 1 * np.eye(n_vars) # regularize for stability\n",
    "    \n",
    "    try:\n",
    "        L = np.linalg.cholesky(cov_mat)\n",
    "        D = np.dot(L, np.random.uniform(0,1, (n_vars, n_obs)))\n",
    "        return D\n",
    "    \n",
    "    except np.linalg.LinAlgError as err:\n",
    "        print('Error ---- Cholesksy')\n",
    "        return None\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.62904718, 0.64037505, 0.44460715],\n",
       "       [0.62904718, 1.        , 0.86393994, 0.25334644],\n",
       "       [0.64037505, 0.86393994, 1.        , 0.24615124],\n",
       "       [0.44460715, 0.25334644, 0.24615124, 1.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "cov_mat = np.array([[1, 0.7, 0.7, 0.5,],\n",
    "             [0.7, 1, 0.95, 0.3],\n",
    "             [0.7, 0.95, 1, 0.3],\n",
    "             [0.5, 0.3, 0.3, 1]])\n",
    "\n",
    "D = create_correlated_dataset(cov_mat)\n",
    "print(D.shape)\n",
    "np.corrcoef(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2500)\n"
     ]
    }
   ],
   "source": [
    "# Construct a cov matrix using a REAL dataset\n",
    "\n",
    "data_dir=\"/data/rmthomas/HeteroSmallSample\"\n",
    "df = pd.read_csv(os.path.join(data_dir, \"real_data.csv\"))\n",
    "df_numeric = df[df.columns[25:125]]\n",
    "cov_mat_overall = df_numeric.corr().values\n",
    "\n",
    "alpha = 0.2\n",
    "reg_cov_mat = cov_mat_overall + alpha*np.eye(100) # alpha makes the matrix well conditioned for Cholesky\n",
    "D_overall = create_correlated_dataset(reg_cov_mat)\n",
    "print(D_overall.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 100 \n",
    "g = df.groupby(['site', 'Dx', 'age_group'])[df.columns[25:25+n_features]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "Groups = list(g.indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate correlation matrices per set = (site, Dx, age_group)\n",
    "corrs_per_set = g.corr().values.reshape(-1, n_features, n_features)\n",
    "#corrs_per_set[np.where(np.isnan(corrs_per_set))] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_labels = [f'f{i}' for i in range(100)] # f1, f2 ...f100\n",
    "data_cols = ['site', 'Dx', 'Age_group'] + feature_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data_all = pd.DataFrame(columns=data_cols) # initialize a dataframe\n",
    "sim_data_group = pd.DataFrame(columns=['site', 'Dx', 'Age_group']) # initialize a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.concat([sim_data_group]*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = create_correlated_dataset(corrs_per_set[corr_i], n_obs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f90</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.579753</td>\n",
       "      <td>0.354048</td>\n",
       "      <td>1.172559</td>\n",
       "      <td>0.477390</td>\n",
       "      <td>1.418456</td>\n",
       "      <td>1.378038</td>\n",
       "      <td>0.648582</td>\n",
       "      <td>1.289229</td>\n",
       "      <td>1.249805</td>\n",
       "      <td>1.236040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485921</td>\n",
       "      <td>0.307701</td>\n",
       "      <td>1.179291</td>\n",
       "      <td>0.794946</td>\n",
       "      <td>1.057373</td>\n",
       "      <td>-0.282628</td>\n",
       "      <td>1.493134</td>\n",
       "      <td>0.718699</td>\n",
       "      <td>0.926573</td>\n",
       "      <td>0.361378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.247798</td>\n",
       "      <td>0.721363</td>\n",
       "      <td>0.913661</td>\n",
       "      <td>0.902886</td>\n",
       "      <td>0.920255</td>\n",
       "      <td>1.250294</td>\n",
       "      <td>0.205790</td>\n",
       "      <td>0.898721</td>\n",
       "      <td>1.422403</td>\n",
       "      <td>0.635937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.646693</td>\n",
       "      <td>0.870319</td>\n",
       "      <td>0.550951</td>\n",
       "      <td>0.783512</td>\n",
       "      <td>0.649794</td>\n",
       "      <td>0.588926</td>\n",
       "      <td>1.582328</td>\n",
       "      <td>0.955295</td>\n",
       "      <td>1.455194</td>\n",
       "      <td>0.917329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.323708</td>\n",
       "      <td>0.850976</td>\n",
       "      <td>0.579934</td>\n",
       "      <td>1.438460</td>\n",
       "      <td>1.077942</td>\n",
       "      <td>1.401805</td>\n",
       "      <td>0.367354</td>\n",
       "      <td>1.618112</td>\n",
       "      <td>0.882814</td>\n",
       "      <td>1.141259</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.519534</td>\n",
       "      <td>1.187627</td>\n",
       "      <td>0.528415</td>\n",
       "      <td>0.690527</td>\n",
       "      <td>1.093244</td>\n",
       "      <td>0.451904</td>\n",
       "      <td>0.666801</td>\n",
       "      <td>0.429912</td>\n",
       "      <td>1.412119</td>\n",
       "      <td>0.456779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.977510</td>\n",
       "      <td>0.222065</td>\n",
       "      <td>1.479338</td>\n",
       "      <td>0.611162</td>\n",
       "      <td>1.243309</td>\n",
       "      <td>0.805549</td>\n",
       "      <td>0.266392</td>\n",
       "      <td>1.566194</td>\n",
       "      <td>1.937155</td>\n",
       "      <td>1.282991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.413174</td>\n",
       "      <td>1.349350</td>\n",
       "      <td>1.122237</td>\n",
       "      <td>1.106723</td>\n",
       "      <td>1.504242</td>\n",
       "      <td>1.100625</td>\n",
       "      <td>1.603293</td>\n",
       "      <td>0.777187</td>\n",
       "      <td>1.828995</td>\n",
       "      <td>1.542503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.860499</td>\n",
       "      <td>1.423681</td>\n",
       "      <td>0.829665</td>\n",
       "      <td>0.442679</td>\n",
       "      <td>1.149462</td>\n",
       "      <td>1.917575</td>\n",
       "      <td>0.355069</td>\n",
       "      <td>1.857625</td>\n",
       "      <td>1.331467</td>\n",
       "      <td>1.601007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.439265</td>\n",
       "      <td>1.300415</td>\n",
       "      <td>0.114586</td>\n",
       "      <td>0.492780</td>\n",
       "      <td>0.557306</td>\n",
       "      <td>0.030590</td>\n",
       "      <td>1.310867</td>\n",
       "      <td>1.044541</td>\n",
       "      <td>1.545986</td>\n",
       "      <td>0.070934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2        f3        f4        f5        f6  \\\n",
       "0  0.579753  0.354048  1.172559  0.477390  1.418456  1.378038  0.648582   \n",
       "1  0.247798  0.721363  0.913661  0.902886  0.920255  1.250294  0.205790   \n",
       "2  0.323708  0.850976  0.579934  1.438460  1.077942  1.401805  0.367354   \n",
       "3  0.977510  0.222065  1.479338  0.611162  1.243309  0.805549  0.266392   \n",
       "4  0.860499  1.423681  0.829665  0.442679  1.149462  1.917575  0.355069   \n",
       "\n",
       "         f7        f8        f9    ...          f90       f91       f92  \\\n",
       "0  1.289229  1.249805  1.236040    ...     0.485921  0.307701  1.179291   \n",
       "1  0.898721  1.422403  0.635937    ...     0.646693  0.870319  0.550951   \n",
       "2  1.618112  0.882814  1.141259    ...    -0.519534  1.187627  0.528415   \n",
       "3  1.566194  1.937155  1.282991    ...     0.413174  1.349350  1.122237   \n",
       "4  1.857625  1.331467  1.601007    ...    -0.439265  1.300415  0.114586   \n",
       "\n",
       "        f93       f94       f95       f96       f97       f98       f99  \n",
       "0  0.794946  1.057373 -0.282628  1.493134  0.718699  0.926573  0.361378  \n",
       "1  0.783512  0.649794  0.588926  1.582328  0.955295  1.455194  0.917329  \n",
       "2  0.690527  1.093244  0.451904  0.666801  0.429912  1.412119  0.456779  \n",
       "3  1.106723  1.504242  1.100625  1.603293  0.777187  1.828995  1.542503  \n",
       "4  0.492780  0.557306  0.030590  1.310867  1.044541  1.545986  0.070934  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_data_group_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error ---- Cholesksy\n",
      "Error ---- Cholesksy\n",
      "Error ---- Cholesksy\n",
      "Error ---- Cholesksy\n",
      "Error ---- Cholesksy\n",
      "Error ---- Cholesksy\n",
      "Error ---- Cholesksy\n",
      "Error ---- Cholesksy\n",
      "Error ---- Cholesksy\n",
      "Error ---- Cholesksy\n",
      "Error ---- Cholesksy\n",
      "Error ---- Cholesksy\n",
      "Error ---- Cholesksy\n",
      "Error ---- Cholesksy\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series\n",
    "\n",
    "min_subj = 5\n",
    "max_subj = 70\n",
    "for corr_i in range(corrs_per_set.shape[0]):\n",
    "    n_obs=np.random.choice(np.arange(min_subj, max_subj))\n",
    "    D = create_correlated_dataset(corrs_per_set[corr_i], n_obs=n_obs)\n",
    "\n",
    "    if D is not None:\n",
    "        sim_data_group = sim_data_group.append(Series(list(Groups[corr_i]), index=['site', 'Dx', 'Age_group']), ignore_index=True)\n",
    "        sim_data_group = pd.concat([sim_data_group]*n_obs)\n",
    "        \n",
    "        sim_data_group_matrix = pd.DataFrame(D.T, columns=feature_labels)\n",
    "        \n",
    "        \n",
    "        sim_data.append(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = np.hstack(sim_data)\n",
    "nvars, nsubjs = all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data for each group\n",
    "D_patients = create_correlated_dataset(cov_patients)\n",
    "D_controls = create_correlated_dataset(cov_controls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gs\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "a = 31\n",
    "if a%2 != 0:\n",
    "    a += 1\n",
    "\n",
    "n = np.floor(np.sqrt(a)).astype(np.int64)\n",
    "\n",
    "while a%n != 0:\n",
    "    n -= 1\n",
    "\n",
    "m = (a/n).astype(np.int64)\n",
    "coords = list(itertools.product(list(range(m)), list(range(n))))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fancyimpute import MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/athi94/investigating-imputation-methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
